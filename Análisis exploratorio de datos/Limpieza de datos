# Lista de paquetes requeridos
paquetes <- c(
  "openxlsx", "fBasics", "psych", "modeest", "ggrepel", "GGally", 
  "mice", "corrplot", "readxl", "doebioresearch", "performance", "dplyr", 
  "ScottKnott", "agricolae", "car", "broom", "data.table", "emmeans", 
  "ggplot2", "tidyverse", "lattice", "nlme", "lme4", "lmerTest", "multcomp", 
  "rstatix", "ggpubr", "see", "MASS", "lsmeans", "scales", "lmtest", "multcompView", 
  "googlesheets4", "googledrive", "clipr", "FactoMineR", "factoextra", 
  "glmmTMB", "DHARMa", "MuMIn", "hnp", "effects", "sjstats", "ExpDes", "sf", "tmap", "terra",
  "RVAideMemoire", "RColorBrewer", "DiagrammeR", "janitor", "missForest")

# Verifica cuáles no están instalados
no_instalados <- paquetes[!(paquetes %in% installed.packages()[,"Package"])];no_instalados

# Instala los que faltan
if(length(no_instalados)) {
  install.packages(no_instalados)
} else {
  message("Todos los paquetes ya están instalados.")
}

# Carga todos los paquetes (opcional)
lapply(paquetes, library, character.only = TRUE)
#################################################################################################

datos<- read_excel("EDA.xlsx", sheet = 1)
view(datos)



##############################################################
#          ANÁLISIS EXPLORATORIO DE DATOS (EDA)
#               Ejemplo aplicado en Agronomía
##############################################################

# Cargar librerías necesarias
library(readxl)
library(dplyr)
library(janitor)
library(ggplot2)
library(tidyr)

##############################################################
#  IMPORTAR Y EXPLORAR LOS DATOS
##############################################################

datos <- read_excel("EDA.xlsx", sheet = 1)
View(datos)

# Estructura inicial
str(datos)
colnames(datos)
head(datos)
tail(datos)

##############################################################
# LIMPIEZA Y CONVERSIÓN DE VARIABLES
##############################################################

# Limpiar nombres de columnas
datos <- clean_names(datos)
names(datos)

# Convertir variables numéricas
numericas <- c("altura", "diametro")
datos[numericas] <- lapply(datos[numericas], as.numeric)

# Convertir variables categóricas
datos$tratamiento <- as.factor(datos$tratamiento)

# Verificación de clases de variables
sapply(datos, class)

##############################################################
# REVISIÓN DE DATOS FALTANTES
##############################################################

# Conteo de valores faltantes por columna
colSums(is.na(datos))

# ---- Imputación simple ----
# Reemplazar los NA con la media o mediana según corresponda

# Imputación por media
datos$altura[is.na(datos$altura)] <- mean(datos$altura, na.rm = TRUE)

# Imputación por mediana
datos$diametro[is.na(datos$diametro)] <- median(datos$diametro, na.rm = TRUE)

# Verificar nuevamente
colSums(is.na(datos[numericas]))

##############################################################
#  DETECCIÓN Y MANEJO DE OUTLIERS
##############################################################

# Función para detectar valores atípicos con el método del IQR
detectar_outliers <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  which(x < (Q1 - 1.5*IQR) | x > (Q3 + 1.5*IQR))
}

# Aplicar la función a las variables numéricas
outliers_lista <- lapply(datos[numericas], detectar_outliers)
outliers_lista

# Identificar filas con outliers
filas_outliers <- unique(unlist(outliers_lista))
length(filas_outliers)

# Crear nuevo conjunto de datos sin outliers
datos_limpios <- datos[-filas_outliers, ]

##############################################################
#  ANÁLISIS GRÁFICO EXPLORATORIO
##############################################################

## --- Boxplots ---
boxplot(datos$diametro ~ datos$tratamiento,
        xlab = "Tratamientos",
        ylab = "Diámetro (cm)",
        col = "lightblue",
        main = "Diagrama de caja del diámetro por tratamiento")

## --- Histograma ---
hist(datos$diametro,
     main = "Distribución del diámetro del tallo",
     xlab = "Diámetro (cm)",
     col = "lightgreen", border = "white")

## --- Gráfico de densidad ---
plot(density(datos$diametro, na.rm = TRUE),
     main = "Densidad del diámetro del tallo",
     xlab = "Diámetro (cm)",
     col = "blue", lwd = 2)

## --- Gráfico de dispersión ---
plot(datos$diametro, datos$altura,
     main = "Relación entre diámetro y altura",
     xlab = "Diámetro (cm)",
     ylab = "Altura (cm)",
     col = "darkorange", pch = 19)

## --- Gráfico de barras (media por tratamiento) ---
medias <- tapply(datos$diametro, datos$tratamiento, mean, na.rm = TRUE)
barplot(medias,
        col = "skyblue",
        main = "Media del diámetro por tratamiento",
        xlab = "Tratamiento",
        ylab = "Diámetro promedio (cm)")

## --- Gráfico de pastel ---
etiquetas <- paste(names(medias), "\n", round(medias, 2))
pie(medias, labels = etiquetas,
    col = rainbow(length(medias)),
    main = "Proporción del diámetro promedio por tratamiento",
    border = "white")

##############################################################
# REVISIÓN FINAL Y RESUMEN ESTADÍSTICO
##############################################################

# Resumen numérico básico
summary(datos[numericas])

# Ver niveles de factores
lapply(datos[c("tratamiento")], levels)













####################################################################################################################################
#ANÁLISIS DE LA BASE DE DATOS
setwd("C:/Users/LUIS/Desktop/USAC 2/9no. semestre/MIAPA/Datos de práctica") #Abrir directorio de trabajo

#Carga de liberías-----------------------------------------------------------------------
install.packages("mice")
install.packages("corrplot")
install.packages("GGally")
install.packages("fBasics")
library(fBasics)
library(GGally)
library(mice) #para realizar imputación múltiple
library(corrplot)
library(readxl)
library(doebioresearch)
library(performance)
library(dplyr)
library(ScottKnott)
library(agricolae)
library(car)
library(broom)
library(data.table)        
library(emmeans)
library(ggplot2)
library(tidyverse)
library(lattice)
library(nlme)
library(lme4)
library(lmerTest)
library(multcomp)
library(rstatix)
library(ggpubr)
library(see)




#Importación de datos---------------------------------------------------
#Importar archivo Excel:
datos<- read_excel("Aserradero.xlsx", sheet = 1)
view(datos)
attach(datos)
  
#Convertir columna de interés (que sea categórica) a factor para realizar ANDEVA:
  
view(datos)
datos$rendimiento<- as.factor(datos$rendimiento) #Para convertir la columna a factor en caso de que la variable sea cualitativa
                                                    #Sustituir rendimiento por la variable categórica 
  
  
  
  
#Importar archivo CSV (delimitado por comas):
data <- read.csv("ruta/al/archivo.csv", stringsAsFactors = FALSE) #stringsAsFactors es para indicar si se desea que las columnas con datos categóricos representan o no factores a ser usados en el ANDEVA (Factor con tratamientos). Si se coloca False se consideran como nombres nada más.
                                                                      #Columna con nombres o caracteres normales: FALSE
                                                                      #col. con tratamientos (Factor para ANDEVA): TRUE
#Importar archivo txt:
data <- read.table("ruta/al/archivo.txt", header = TRUE, sep = "\t", stringsAsFactors = FALSE) #StringsAsFactors es aplicable para read.CSV y read.table ya q se derivan de la misma fx. No aplica para read.excel
                                                                                #header=TRUE indica que la primera fila serán los nombres de las columnas
                                                                                #sep="\t" es la tabulación por la que se separaran las columnas
  
  
  
  
  
  
  
#Exploración inicial de datos-----------------------------------------------
str(datos) #Estructura de los datos: indica nombre de las columnas, el número de datos, número de filas y columnas
dim(datos) #No.filas y columnas del dataframe
summary(datos) #Resumen de medidas de tendencia central y dispersión (media, mediana, cuartiles, max, min)
head(datos) #Primeros y ultimos 6 datos 
tail(datos)  

  
#Manejo de datos faltantes--------------------------------------------------------
            
              #Tipos de datos faltantes:
                  # 1) DF completamente al azar: puede imputarse con media, mediana, moda (datos categ)
                  # 2) DF al azar: imputar con PMM o con mediana o con distrib normal
                  # 3) DF no aleatorios: imputar con PMM o con KNN


#Verificar si hay datos faltantes en el dataframe:

anyNA(datos) #para verificar si hay datos faltantes en la base de datos
is.na(datos) #para saber en que filas y columnas se localizan los datos faltantes en el dataframe
colSums((is.na(datos))) # Contar los NA por columna:
faltantes <- colSums(is.na(datos))
datos_faltantes <- data.frame(Variable = names(faltantes), Faltantes = faltantes) # Convertir a data frame

# Graficar
ggplot(datos_faltantes, aes(x = Variable, y = Faltantes)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Datos faltantes por variable") +
  theme_minimal()



  
# Manejo de datos faltantes (NA):
    
# 1) Eliminar NA:
na.omit(datos) 
datos_limpios<- na.omit(datos)
view(datos_limpios)
    
    
    
    
# 2) Imputación simple (a través de la media):
    
rendimiento_media<- datos %>%
mutate("rendimiento" = ifelse(is.na(rendimiento), mean(rendimiento, na.rm = TRUE), rendimiento))
    
    #Estructura básica de ifelse: ifelse(condición, valor_si_verdadero, valor_si_falso)
    #Indica que si hay datos faltantes, entonces rellenar con la media, si no; dejar el valor original
    #Al usar el operador pipe (%>%) no hay necesidad de colocar datos%rendimiento para acceder a la columna rendimiento
    # pipe sirve para encadenar "datos" a la fx mutate. Mutate adiciona o modifica las columnas con la instrucción de "ifelse".                                                      

rendimiento_media #Correr para verificar si se sustituyeron los datos faltantes

#Gráfico de dens. prob (datos originales vs imputados):
plot(density(datos$rendimiento, na.rm = TRUE), col="red", xlab = "Rendimiento", ylab = "Densidad de prob.", main = "Imputación (media)")
lines(density(rendimiento_media$rendimiento), col = "blue")
    
    legend("topright",                      
           legend = c("Original", "Imputado (media)"),
           col = c("red", "blue"),          
           lty = 1,                         
           cex = 0.6)       
    
    
    
    
# 3) Imputación simple (a través de la mediana: es una forma más robusta de imputar cuando no hay claridad sobre la distribución de los datos, anula el efecto de outliers)
    
rendimiento_mediana<- datos %>%
  mutate("rendimiento" = ifelse(is.na(rendimiento), median(rendimiento, na.rm = TRUE), rendimiento))
    
rendimiento_mediana #correr para verificar si la imputación fue exitosa

plot(density(datos$rendimiento, na.rm = TRUE), col="red", xlab = "Rendimiento", ylab = "Densidad de prob.", main = "Imputación (mediana)")
lines(density(rendimiento_mediana$rendimiento), col = "blue")
    
    legend("topright",                      
           legend = c("Original", "Imputado (media)"),
           col = c("red", "blue"),          
           lty = 2,                         
           cex = 0.4)
  

      

# 4) Imputación mediante la distribución normal (solo si los datos son biométricos):
media<- mean(datos$rendimiento, na.rm = TRUE)
DE<- sd(datos$rendimiento, na.rm = TRUE)
conteo_NA<- sum(is.na(datos$rendimiento))
datos_imputados<- rnorm(conteo_NA, mean = media, sd = DE)
print(datos_imputados)
datos_nuevos<- datos
datos_nuevos$rendimiento[is.na(datos_nuevos$rendimiento)]<- datos_imputados #Se introdujeron los datos nuevos o imputados a la columna de interés


    # Comparación gráfica de las distribuciones (datos originales vs normal):
ggplot(datos, aes(x = rendimiento)) +
  geom_density(color = "blue", linewidth = 1.2, fill = "blue", alpha = 0.3) +
  stat_function(fun = dnorm, args = list(mean = media, sd = DE), color = "red", linetype = "dashed", linewidth = 1.2) +
  labs(title = "Comparación entre densidad empírica y normal", x = "Rendimiento", y = "Densidad de probabilidad") +
  theme_minimal() + xlim(2000, 10000)
  
    # Curva de dens. prob de datos originales e imputados:
plot(density(datos$rendimiento, na.rm = T), col = "red", xlab = "Rendimiento", ylab = "Densidad de prob.", main = "Imputación (D. normal)")
lines(density(datos_nuevos$rendimiento), col = "blue")

legend("topright",                      
       legend = c("Original", "Imputado (PMM)"),
       col = c("red", "blue"),          
       lty = 1,                         
       cex = 0.45)



# 5) Imputación múltiple por coincidencia de media predictiva (PMM):

    #Verificar si hay relación lineal entre las variables mediante análisis de correlación:
head(datos)
cor(`peso total`, rendimiento, use = "complete.obs")    
modelo<- lm(rendimiento ~ `peso total`)
summary(modelo)
plot(`peso total`, rendimiento)
abline(modelo, lwd=2, col = "red")


        # PMM cuando se toma solo un dataset
imputado<- mice(datos, method = "pmm", seed = 123, m = 5) # m es el número de datasets, seed indica q los resultados serán reproducibles
summary(imputado) #para ver en qué columna se aplicó la imputación
imputado$imp$rendimiento #para visualizar cuales fueron los valores imputados
datos_imputados<- complete(imputado, 1) #para seleccionar uno de los 5 conjuntos de datos creados
print(datos_imputados)

      # Diagrama de dispersión: datos imputados vs originales

plot(datos$`peso total`, datos$rendimiento, col = "red", pch = 16,
     xlab = "Peso total", ylab = "Rendimiento", main = "Datos originales vs imputados")

points(datos_imputados$`peso total`, datos_imputados$rendimiento, col = "blue", pch = 1)
legend("bottomright", legend = c("Original", "Imputado"), col = c("red", "blue"), pch = c(16,1))


      # Curva de densidad de probabilidad: datos imputados vs originales

plot(density(datos$rendimiento, na.rm = TRUE), col="red", xlab = "Rendimiento", ylab = "Densidad de prob.", main = "Imputación (PMM)")
lines(density(datos_imputados$rendimiento), col = "blue")

legend("topright",                      
       legend = c("Original", "Imputado (PMM)"),
       col = c("red", "blue"),          
       lty = 1,                         
       cex = 0.6)

#Limpieza de la base de datos-----------------------------------------------------------------------
  #Detección y corrección de errores en los datos
    #Visualizar valores atípicos
boxplot(datos$rendimiento)
outliers<- boxplot(datos$rendimiento, plot = FALSE)$out #para saber qué dato es el atípico
Q1<- quantile(datos$rendimiento, 0.25, na.rm = TRUE)
Q3<- quantile(datos$rendimiento, 0.75, na.rm = T )
IQR<- Q3-Q1
limite_superior<- Q3+1.5*IQR
limite_inferior<- Q1-1.5*IQR
which(datos$rendimiento %in% outliers) #Indica la fila en la que se encuentra el valor atípico según la columna analizada

datos$outlier<- ifelse(datos$rendimiento < limite_inferior| datos$rendimiento>limite_superior, "si","no") #crea una columna para indicar qué datos son atípicos y cuáles no

ggplot(datos, aes(x = "", y = rendimiento)) +
  geom_boxplot(outlier.colour = "red", outlier.size = 3) +
  labs(title = "Boxplot de rendimiento con outliers en rojo", y = "Rendimiento") +
  theme_minimal()

    #Identificación de valores extremos
summary(datos$rendimiento)
    #Identificar valores únicos de la variable
unique(datos$rendimiento)
  
  #Normalización de datos al mismo formato
datos$rendimiento<- as.factor(datos$rendimiento) #para convertir a factor la columna de los tratamientos
datos$rendimiento<- as.numeric(datos$rendimiento) #convertir la variable respuesta a datos

  #Corrección de nombres de los tratamientos (todos en minúscula)
datos$rendimiento<- tolower(trimws(datos$rendimiento))

  #Eliminar datos duplicados
datos<- datos[!duplicated(datos), ]

  # Matriz de correlación para identificación de correlaciones sospechosas entre variables numéricas (indicativo de errores)
matriz_cor<- cor(datos[, sapply(datos, is.numeric)], use = "complete.obs")
  #Mapa de calor (Pearson):
corrplot(matriz_cor, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, addCoef.col = "black")
  #Matriz de correlación
GGally::ggpairs(datos[, sapply(datos, is.numeric)])

  #Limpiar errores de digitación:
# Eliminar espacios en blanco antes y después
datos$rendimiento <- trimws(datos$rendimiento) #Aplicar sobre factores con tratamientos categóricos

#Detectar filas duplicadas

duplicados <- datos[duplicated(datos), ]
print(duplicados)
datos <- datos[!duplicated(datos), ] #Eliminar duplicados

#Corrección de errores de unidad o escala (ej: datos que no corresponan a 100 kg/ha, que soprepasen ese valor)

  # Visualizar valores extremos
boxplot(datos$rendimiento, main = "Boxplot para detectar posibles errores de unidad")

  # Ver valores mayores a cierto umbral
datos[datos$rendimiento > 5000, ]  # Ajusta el umbral según la variable

# Unificar nombres (todo mayúscula y sin espacios)
datos$rendimiento <- toupper(trimws(datos$rendimiento)) #Para columna de los tratamientos

####################################################################################################################










# IDENTIFICACIÓN DE VALORES ATÍPICOS


# Lista de paquetes requeridos
paquetes <- c(
  "openxlsx", "fBasics", "psych", "modeest", "ggrepel", "GGally", 
  "mice", "corrplot", "readxl", "doebioresearch", "performance", "dplyr", 
  "ScottKnott", "agricolae", "car", "broom", "data.table", "emmeans", 
  "ggplot2", "tidyverse", "lattice", "nlme", "lme4", "lmerTest", "multcomp", 
  "rstatix", "ggpubr", "see", "MASS", "lsmeans", "scales", "lmtest", "multcompView", 
  "googlesheets4", "googledrive", "clipr", "FactoMineR", "factoextra", 
  "glmmTMB", "DHARMa", "MuMIn", "hnp", "effects", "sjstats", "ExpDes", "sf", "tmap", "terra",
  "RVAideMemoire", "RColorBrewer", "DiagrammeR", "janitor", "missForest")

# Verifica cuáles no están instalados
no_instalados <- paquetes[!(paquetes %in% installed.packages()[,"Package"])];no_instalados

# Instala los que faltan
if(length(no_instalados)) {
  install.packages(no_instalados)
} else {
  message("Todos los paquetes ya están instalados.")
}

# Carga todos los paquetes (opcional)
lapply(paquetes, library, character.only = TRUE)
#################################################################################################
excel_sheets("Concepción Rotación.xlsx")
datos<- read_excel("Concepción Rotación.xlsx", sheet = 2)
attach(datos)
view(datos)

install.packages("DataExplorer")
library(DataExplorer)
create_report(datos)

# Activar con ESQUISSE en Addins #Para crear gráficos
install.packages("esquisse")
library(esquisse)


install.packages("dlookr")
library(dlookr)

#Diagnóstico exploratorio
diagnose(datos)
plot_na_pareto(datos) #grafica de datos faltantes: si no los hay, tira error
diagnose_na(datos)

#Valores atipicos 
plot_outlier(datos)
diagnose_outlier(datos)
outliers <- find_outlier(datos)


#Análisis descriptivo
names(datos)
describe(datos)
describe_by(datos, "Tratamiento") #para ver estadísticas por tratamiento

#Distribuciones
plot_density(datos)

#Imputación
imputed <- imputate_na(datos)

#Imputación por cada variable
imputed <- imputate_na(datos, Total_Plantas)

#Eliminar valores atípicos
datos_sin_out <- datos %>% remove_outlier()




datos <- datos %>%
  mutate(
    outlier_Total_Plantas = ifelse(Total_Plantas %in% boxplot.stats(Total_Plantas)$out, TRUE, FALSE),
    outlier_Peso_Kg = ifelse(Peso_Kg %in% boxplot.stats(Peso_Kg)$out, TRUE, FALSE)
  )

# Filas que tienen algún outlier
outlier_rows <- datos %>%
  filter(outlier_Total_Plantas == TRUE | outlier_Peso_Kg == TRUE)

outlier_rows

#Eliminar atípicos
datos_sin_out <- datos %>%
  filter(!outlier_Total_Plantas & !outlier_Peso_Kg)

view(datos_sin_out)



#Prueba de Grubbs

names(datos)
install.packages("outliers")
library(outliers)

grubbs.test(datos$peso_kg)

outlier(datos$peso_kg)

grubbs.test(datos$total_plantas)

outlier(datos$total_plantas)


# Prueba de Grubbs en bucle:

library(outliers)

x <- datos$total_plantas

repeat {
  test <- grubbs.test(x)
  print(test)
  
  if (test$p.value < 0.05) {
    # Detectar si el outlier es el más alto o el más bajo
    if (grepl("highest", test$alternative)) {
      outlier_value <- max(x)
    } else {
      outlier_value <- min(x)
    }
    cat("Eliminando outlier:", outlier_value, "\n")
    x <- x[x != outlier_value]
  } else {
    break
  }
}

# Resultado limpio
x

attach(datos)
# Box-plot para detectar valores atípicos
names(datos)
boxPlot(datos$total_plantas ~ datos$tratamiento)
a=boxplot(datos$total_plantas ~ datos$tratamiento)
a


tapply(datos$total_plantas, datos$tratamiento, boxplot.stats)

#----------------------------------------------------------------------
install.packages("dplyr")
install.packages("rstatix")
library(dplyr)
library(rstatix)


